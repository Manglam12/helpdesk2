<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta meta name="viewport" content="width=device-width, user-scalable=no" />
    <title>Helpdesk</title>
</head>
   
<script
	src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.10.2/dist/umd/popper.min.js"
	integrity="sha384-7+zCNj/IqJ95wo16oMtfsKbZ9ccEh31eOz1HGyDuCQ6wgnyJNSYdrPa03rtR1zdB"
	crossorigin="anonymous"
></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js"></script>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-T3c6CoIi6uLrA9TneNEoa7RxnatzjcDSCmG1MXxSR1GAsXEV/Dwwykc2MPK8M2HN" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<link
	rel="stylesheet"
	href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.7.2/font/bootstrap-icons.css"
/>
<link rel="icon" href="assets/images/logo.png" type="image/png">
<link rel="stylesheet" type="text/css" href="../assets/css/style.css" />
<script src="../assets/js/script.js"></script>
<style>
 
  </style>
<body> 
  <header class="navbar navbar-expand-md d-flex flex-wrap justify-content-center mt-2 p-2 mb-2 border-bottom">
   <div id="top_bar">
    <a href="#" class="d-flex align-items-center mb-3 mb-md-0 me-md-auto link-body-emphasis text-decoration-none">
      <img src="../assets/images/logo.png" id="imglogo">
      <span class="fs-4 mr-5 lo"><h2 class="bold-text">Helpdesk</h2></span>
    </a>
   </div>
    <div class="container-fluid" id="sec_nav">
      <button class="navbar-toggler" type="button" onclick="openLeftSidebar()">
      <span class="navbar-toggler-icon"></span>
      </button>
     <div id="leftSidebar" class="sidebar-left">
      <a href="javascript:void(0)" class="closebtn" onclick="closeLeftSidebar()">&times;</a>
      <h2>semester 5</h2>
      <a href="../semester5/index.html">Software tech.</a>
      <a href="../semester5/formal.html">Formal lang.</a>
      <a href="../semester5/ai.html">AI</a>
      <a href="../semester5/ml.html">ML</a>
      <a href="../semester5/const.html">Indian Const.</a>
      <a href="../semester5/comp_netw.html">Comp. Networks</a>
      <a href="../semester5/big.html" class="active">Big Data</a>
      <a href="../semester5/cloud.html">Cloud Computing</a>

      <h2>semester 6</h2>
      <a href="#">Comming Soon....</a>
     
  </div>
  <div class="semester">semester-5</div>

      <button class="navbar-toggler" type="button" data-bs-toggle="collapse" id="upper_menu_btn" data-bs-target="#collapsibleNavbar">
 <i class="fa fa-arrow-down" aria-hidden="true"></i>      </button>
      <div class="collapse navbar-collapse" id="collapsibleNavbar" >
        <ul class="nav nav-pills navbar-nav ms-auto" id="myNav">
          <!-- 1st Year -->
          <li class="nav-item">
            <a class="nav-link" href="../semester1/index.html">1st Year</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="../semester3/index.html">2nd Year</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="../semester5/index.html">3rd Year</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="../semester7/index.html">4th Year</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="../NPTEL/index.html">NPTEL</a>
          </li>
        </ul>
      </div>
    </div>
  </header>
  
  
    <div id="body">
      <div class="heading_name">Big Data</div>
      <div id="watermark">@Debuggers</div>

      <div id="up">
        <a href="#" id="goToTopButton" class="go-to-top-button">
          <span><i class="fa fa-arrow-up" aria-hidden="true" id="arrow"></i></span>
      </a>
      </div>  
     
      <h3>Digital Data and Big Data Concepts</h3>

      <h4>1. Types of Digital Data</h4>
      <p><strong>Digital Data</strong> refers to data that is represented in a binary format (0s and 1s) and can be processed by computers. It can be categorized into several types:</p>
      <ul>
          <li><strong>Structured Data:</strong> Data that is organized in a fixed format, such as databases and spreadsheets. Examples include customer names, addresses, and transactions.</li>
          <li><strong>Unstructured Data:</strong> Data that does not have a predefined format or structure. Examples include text documents, emails, social media posts, and multimedia files (images, videos).</li>
          <li><strong>Semi-Structured Data:</strong> Data that has some organizational properties but does not fit into a rigid structure. Examples include XML files, JSON data, and logs.</li>
      </ul>
  
      <h4>2. Introduction to Big Data</h4>
      <p><strong>Big Data</strong> refers to large and complex datasets that are difficult to process using traditional data processing tools. Characteristics of Big Data include:</p>
      <ul>
          <li><strong>Volume:</strong> The sheer amount of data being generated.</li>
          <li><strong>Velocity:</strong> The speed at which data is generated and processed.</li>
          <li><strong>Variety:</strong> The different types of data (structured, unstructured, semi-structured).</li>
          <li><strong>Veracity:</strong> The uncertainty or quality of the data.</li>
      </ul>
  
      <h4>3. Big Data Analytics</h4>
      <p><strong>Big Data Analytics</strong> involves using advanced analytical techniques and technologies to extract insights from large datasets. It includes:</p>
      <ul>
          <li><strong>Descriptive Analytics:</strong> Analyzing historical data to understand what happened.</li>
          <li><strong>Predictive Analytics:</strong> Using data to predict future trends and behaviors.</li>
          <li><strong>Prescriptive Analytics:</strong> Providing recommendations for actions based on data analysis.</li>
      </ul>
  
      <h4>4. History of Hadoop</h4>
      <p><strong>Hadoop</strong> is an open-source framework for distributed storage and processing of large datasets. Its history includes:</p>
      <ul>
          <li><strong>2005:</strong> Hadoop was created by Doug Cutting and Mike Cafarella as part of the Nutch project.</li>
          <li><strong>2006:</strong> Hadoop became a top-level project at the Apache Software Foundation.</li>
          <li><strong>2011:</strong> The Hadoop ecosystem grew with the introduction of tools like HBase, Hive, and Pig.</li>
      </ul>
  
      <h4>5. Apache Hadoop</h4>
      <p><strong>Apache Hadoop</strong> is a framework that enables distributed processing of large datasets across clusters of computers. Key components include:</p>
      <ul>
          <li><strong>Hadoop Distributed File System (HDFS):</strong> A scalable and fault-tolerant file system for storing large data files.</li>
          <li><strong>MapReduce:</strong> A programming model for processing large datasets in parallel.</li>
          <li><strong>YARN (Yet Another Resource Negotiator):</strong> A resource management layer that schedules and manages resources in the Hadoop cluster.</li>
      </ul>
  
      <h4>6. Analyzing Data with Unix Tools</h4>
      <p><strong>Unix Tools</strong> are command-line utilities used for processing and analyzing data. Some commonly used tools include:</p>
      <ul>
          <li><strong>grep:</strong> Searches for patterns in text files.</li>
          <li><strong>awk:</strong> A programming language for pattern scanning and processing.</li>
          <li><strong>sed:</strong> A stream editor for filtering and transforming text.</li>
          <li><strong>sort:</strong> Sorts lines of text files.</li>
          <li><strong>cut:</strong> Removes sections from each line of files.</li>
      </ul>
  
      <h4>7. Analyzing Data with Hadoop</h4>
      <p><strong>Analyzing Data with Hadoop</strong> involves using Hadoop's ecosystem to process and analyze large datasets. Techniques include:</p>
      <ul>
          <li><strong>MapReduce Jobs:</strong> Writing MapReduce programs to process data in parallel across a Hadoop cluster.</li>
          <li><strong>Hive:</strong> A data warehouse tool that provides an SQL-like interface for querying and managing data stored in HDFS.</li>
          <li><strong>Pig:</strong> A high-level scripting language for processing and analyzing data in Hadoop.</li>
          <li><strong>HBase:</strong> A distributed, scalable database that runs on top of HDFS and provides real-time access to data.</li>
      </ul>
      <h3>Databases and Big Data Concepts</h3>

      <h4>1. Databases and Relational Algebra</h4>
      <p><strong>Databases</strong> are structured collections of data that can be easily accessed, managed, and updated. The relational model organizes data into tables (relations) with rows and columns. <strong>Relational Algebra</strong> is a theoretical framework for querying and manipulating relational databases. It includes operations such as:</p>
      <ul>
          <li><strong>Select:</strong> Retrieves rows that satisfy a given condition.</li>
          <li><strong>Project:</strong> Retrieves specific columns from a table.</li>
          <li><strong>Join:</strong> Combines rows from two or more tables based on a related column.</li>
          <li><strong>Union:</strong> Combines the results of two queries, removing duplicates.</li>
          <li><strong>Difference:</strong> Retrieves rows from one table that are not in another.</li>
      </ul>
  
      <h4>2. Parallel Databases</h4>
      <p><strong>Parallel Databases</strong> use multiple processors to perform operations on large datasets in parallel, improving performance and scalability. Key aspects include:</p>
      <ul>
          <li><strong>Parallel Query Processing:</strong> Distributing the execution of a query across multiple processors to speed up response time.</li>
          <li><strong>In-Database Analytics:</strong> Performing analytical operations within the database system itself, reducing the need to move data.</li>
      </ul>
  
      <h4>3. MapReduce</h4>
      <p><strong>MapReduce</strong> is a programming model used for processing and generating large datasets. It consists of two main phases:</p>
      <ul>
          <li><strong>Map:</strong> Processes input data and produces intermediate key-value pairs.</li>
          <li><strong>Reduce:</strong> Aggregates intermediate data based on the key to produce the final output.</li>
      </ul>
  
      <h4>4. Hadoop</h4>
      <p><strong>Hadoop</strong> is an open-source framework that supports the distributed processing of large datasets across clusters of computers. Key components include:</p>
      <ul>
          <li><strong>HDFS (Hadoop Distributed File System):</strong> A scalable and fault-tolerant file system for storing large files across multiple machines.</li>
          <li><strong>MapReduce:</strong> A programming model for processing data in parallel across a Hadoop cluster.</li>
      </ul>
  
      <h4>5. The Design of HDFS</h4>
      <p><strong>HDFS</strong> is designed to store vast amounts of data across multiple servers while providing high throughput and fault tolerance. Key concepts include:</p>
      <ul>
          <li><strong>Blocks:</strong> Files are split into fixed-size blocks, which are replicated across multiple nodes.</li>
          <li><strong>NameNode:</strong> Manages the metadata and namespace of the file system.</li>
          <li><strong>DataNodes:</strong> Store the actual data blocks and handle read and write requests.</li>
      </ul>
  
      <h4>6. Command Line Interface</h4>
      <p><strong>HDFS Command Line Interface (CLI)</strong> allows users to interact with the Hadoop file system. Common commands include:</p>
      <ul>
          <li><strong>hdfs dfs -ls:</strong> Lists files and directories in HDFS.</li>
          <li><strong>hdfs dfs -put:</strong> Uploads files to HDFS.</li>
          <li><strong>hdfs dfs -get:</strong> Downloads files from HDFS.</li>
      </ul>
  
      <h4>7. Hadoop File System Interface and Relationship to Databases</h4>
      <p><strong>Hadoop File System Interface</strong> provides access to HDFS, which can be integrated with traditional databases for analytics and data processing. Differences between HDFS and traditional databases include:</p>
      <ul>
          <li><strong>Schema:</strong> HDFS is schema-less, while traditional databases have a fixed schema.</li>
          <li><strong>Query Language:</strong> HDFS uses MapReduce, while traditional databases use SQL.</li>
          <li><strong>Data Storage:</strong> HDFS is optimized for large-scale data processing, while traditional databases are optimized for transaction processing.</li>
      </ul>
  
      <h4>8. Algorithms, Extensions, and Languages</h4>
      <p><strong>Algorithms</strong> used in Hadoop include sorting, filtering, and aggregating data in MapReduce jobs. <strong>Extensions</strong> such as Hive and Pig provide higher-level abstractions for querying and processing data. <strong>Languages</strong> used include:</p>
      <ul>
          <li><strong>Java:</strong> Primary language for writing MapReduce programs.</li>
          <li><strong>SQL:</strong> Used with Hive for querying data in HDFS.</li>
          <li><strong>Pig Latin:</strong> A scripting language for processing data in Pig.</li>
      </ul>
  
      <h4>9. Key-Value Stores and NoSQL</h4>
      <p><strong>Key-Value Stores</strong> are a type of NoSQL database where each data item is stored as a key-value pair. Examples include:</p>
      <ul>
          <li><strong>Redis:</strong> An in-memory key-value store.</li>
          <li><strong>Riak:</strong> A distributed key-value store with high availability.</li>
      </ul>
      <p><strong>NoSQL Databases</strong> are designed to handle unstructured and semi-structured data. They include:</p>
      <ul>
          <li><strong>Document Stores:</strong> Store data as documents (e.g., MongoDB).</li>
          <li><strong>Column Stores:</strong> Store data in columns rather than rows (e.g., Cassandra).</li>
          <li><strong>Graph Databases:</strong> Store data as nodes and edges (e.g., Neo4j).</li>
      </ul>
      <p><strong>Tradeoffs between SQL and NoSQL:</strong></p>
      <ul>
          <li><strong>SQL:</strong> Provides ACID properties (Atomicity, Consistency, Isolation, Durability) and is suitable for structured data and complex queries.</li>
          <li><strong>NoSQL:</strong> Offers flexibility in data models, scalability, and high performance for large-scale data and real-time applications.</li>
      </ul>
    
        </body>
</html>